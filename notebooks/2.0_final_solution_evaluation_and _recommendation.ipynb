{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading dataset\n"
      ],
      "metadata": {
        "id": "V6rMe5uxdUuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "def download_and_unzip(url, extract_to='.'):\n",
        "    http_response = urlopen(url)\n",
        "    zipfile = ZipFile(BytesIO(http_response.read()))\n",
        "    zipfile.extractall(path=extract_to)\n",
        "\n",
        "\n",
        "download_and_unzip(\"https://files.grouplens.org/datasets/movielens/ml-100k.zip\",\n",
        "                   extract_to='.')"
      ],
      "metadata": {
        "id": "Ss90qQLfdTPq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_LPed5cuAEa"
      },
      "source": [
        "Next, let's import all of the modules that we'll use in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y9fonQcxt3do"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Third-party imports\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn import preprocessing as pp\n",
        "from sklearn import ensemble as ens\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.sparse as sp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bulding training and testing datasets\n",
        "\n",
        "I will use already splitted train and test datasets - ua.base, ua.test"
      ],
      "metadata": {
        "id": "BvAGcOMgdcCN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g0Nuptl1RATp"
      },
      "outputs": [],
      "source": [
        "def make_dfs():\n",
        "  columns_name=['user_id','item_id','rating','timestamp']\n",
        "  train_df = pd.read_csv(\"./ml-100k/ua.base\",sep=\"\\t\",names=columns_name)\n",
        "  test_df = pd.read_csv(\"./ml-100k/ua.test\",sep=\"\\t\",names=columns_name)\n",
        "\n",
        "  return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "diJHiO6nSImi"
      },
      "outputs": [],
      "source": [
        "def preproc(train_df, test_df):\n",
        "  film_columns = [\"item_id\", \"movie title\", \"release date\", \"video release date\",\n",
        "              \"IMDb URL\", \"unknown\", \"Action\", \"Adventure\", \"Animation\",\n",
        "              \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\",\n",
        "              \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\",\n",
        "              \"Thriller\", \"War\", \"Western\"]\n",
        "\n",
        "  films_df = pd.read_csv(\"./ml-100k/u.item\", sep=\"|\", names=film_columns, encoding='latin-1')\n",
        "  films_df.drop([\"movie title\", \"release date\", \"IMDb URL\", \"unknown\", \"video release date\"], axis = 1, inplace = True)\n",
        "\n",
        "  train_df = pd.merge(train_df, films_df, how='left', left_on='item_id', right_on='item_id')\n",
        "  test_df = pd.merge(test_df, films_df, how='left', left_on='item_id', right_on='item_id')\n",
        "\n",
        "  user_columns = [\"user_id\", \"age\", \"sex\", \"occupation\", \"zip_code\"]\n",
        "  user_df = pd.read_csv(\"./ml-100k/u.user\", sep=\"|\", names=user_columns, encoding='latin-1')\n",
        "  user_df[\"sex\"] = pp.LabelEncoder().fit_transform(user_df[\"sex\"])\n",
        "  occup_df = pd.read_csv(\"./ml-100k/u.occupation\", sep=\"\\t\", names=[\"jobs\"])\n",
        "  le = pp.LabelEncoder()\n",
        "  le.fit(occup_df[\"jobs\"])\n",
        "  user_df[\"occupation\"] = le.transform(user_df[\"occupation\"])\n",
        "  user_df.drop([\"zip_code\"], axis = 1, inplace = True)\n",
        "\n",
        "  train_df = pd.merge(train_df, user_df, how='left', left_on='user_id', right_on='user_id')\n",
        "  test_df = pd.merge(test_df, user_df, how='left', left_on='user_id', right_on='user_id')\n",
        "\n",
        "  train_df.drop([\"item_id\", \"user_id\", \"timestamp\"], axis = 1, inplace = True)\n",
        "  train_y = train_df[\"rating\"].values\n",
        "  train_x = train_df.drop('rating', axis=1).values\n",
        "\n",
        "  test_df.drop([\"item_id\", \"user_id\", \"timestamp\"], axis = 1, inplace = True)\n",
        "  test_y = test_df[\"rating\"].values\n",
        "  test_x = test_df.drop('rating', axis=1).values\n",
        "\n",
        "  print(train_df.info())\n",
        "  return train_x, train_y, test_x, test_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3Kd3_Al5ZaJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "032921c8-b305-4bd3-aacb-5c2d7ad6a4e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 90570 entries, 0 to 90569\n",
            "Data columns (total 22 columns):\n",
            " #   Column       Non-Null Count  Dtype\n",
            "---  ------       --------------  -----\n",
            " 0   rating       90570 non-null  int64\n",
            " 1   Action       90570 non-null  int64\n",
            " 2   Adventure    90570 non-null  int64\n",
            " 3   Animation    90570 non-null  int64\n",
            " 4   Children's   90570 non-null  int64\n",
            " 5   Comedy       90570 non-null  int64\n",
            " 6   Crime        90570 non-null  int64\n",
            " 7   Documentary  90570 non-null  int64\n",
            " 8   Drama        90570 non-null  int64\n",
            " 9   Fantasy      90570 non-null  int64\n",
            " 10  Film-Noir    90570 non-null  int64\n",
            " 11  Horror       90570 non-null  int64\n",
            " 12  Musical      90570 non-null  int64\n",
            " 13  Mystery      90570 non-null  int64\n",
            " 14  Romance      90570 non-null  int64\n",
            " 15  Sci-Fi       90570 non-null  int64\n",
            " 16  Thriller     90570 non-null  int64\n",
            " 17  War          90570 non-null  int64\n",
            " 18  Western      90570 non-null  int64\n",
            " 19  age          90570 non-null  int64\n",
            " 20  sex          90570 non-null  int64\n",
            " 21  occupation   90570 non-null  int64\n",
            "dtypes: int64(22)\n",
            "memory usage: 15.9 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "train_df, test_df = make_dfs()\n",
        "train_x, train_y, test_x, test_y = preproc(train_df, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_user_lines = {} # Getting useful data for recommendation\n",
        "test_items = []\n",
        "for i, data in test_df.iterrows():\n",
        "  test_items.append(data[\"item_id\"])\n",
        "  if data[\"user_id\"] not in test_user_lines.keys():\n",
        "    test_user_lines[data[\"user_id\"]] = [i]\n",
        "  else:\n",
        "    test_user_lines[data[\"user_id\"]].append(i)"
      ],
      "metadata": {
        "id": "V3XBWJ4zxlEf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using best pipeline I got from tpot:"
      ],
      "metadata": {
        "id": "LNC70EfmfCab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = ens.RandomForestClassifier(bootstrap=True, criterion=\"gini\", max_features=0.55, min_samples_leaf=19, min_samples_split=17, n_estimators=100)\n",
        "clf.fit(train_x, train_y)\n",
        "clf.score(test_x, test_y) # Accuracy may not be high, but we our main concern is not accuracy for this task"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlVyQ5z_66s4",
        "outputId": "b4aec945-029c-4e34-9085-601aeacfdd2c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36903499469777307"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating model\n",
        "As the main metric for evaluating my system I decided to use\n",
        "ndcg score. I chose it because of non-binary notions of relevance, in our case ratings."
      ],
      "metadata": {
        "id": "Gtp5MhIxfe2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [] # Predictions\n",
        "for i in range(len(test_y)):\n",
        "  pred = clf.predict(test_x[i, :].reshape(1, -1))\n",
        "  preds.append(pred[0])"
      ],
      "metadata": {
        "id": "FXgyD2ED9WrR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Mean absolute error: \",  mean_absolute_error(test_y, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkhw8EA0-UKg",
        "outputId": "c1ac28a3-1c89-44be-f8ba-d239ec0ea3e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error:  0.8656415694591728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_ndcg(user_id):\n",
        "  predictions = [[clf.predict(test_x[j, :].reshape(1, -1))[0] for j in test_user_lines[user_id]]]\n",
        "  real_rating = [[test_y[j] for j in test_user_lines[user_id]]]\n",
        "\n",
        "  return ndcg_score(real_rating, predictions)"
      ],
      "metadata": {
        "id": "r9fbCMdJAzcD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate():\n",
        "  ndcg = 0\n",
        "  total = 0\n",
        "  for i in test_user_lines.keys():\n",
        "    total += 1\n",
        "    ndcg += find_ndcg(i)\n",
        "  return ndcg / total"
      ],
      "metadata": {
        "id": "-HSicWLDy6oh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean ndcg score: \", evaluate()) #  As you see, result is not bad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77d6ee5-1655-4a7b-b751-7d4a5c1058e4",
        "id": "lEnaIgCea5vy"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ndcg score:  0.9288102407423298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommendation example:"
      ],
      "metadata": {
        "id": "JwgWE9yIfxNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_10(user_id): # Since for testing I use ua.test, where each user got\n",
        "  # exactly 10 ratings, I will recommend user 10 movies based on my predicted ratings\n",
        "  # of movies\n",
        "  predictions = [clf.predict(test_x[j, :].reshape(1, -1))[0] for j in test_user_lines[user_id]]\n",
        "  real_rating = [test_y[j] for j in test_user_lines[user_id]]\n",
        "  recommendations = [[test_items[i]] for i in test_user_lines[user_id]]\n",
        "  for i in range(len(predictions)):\n",
        "    recommendations[i].append(predictions[i])\n",
        "  recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  ideal_recommendations = [[test_items[i]] for i in test_user_lines[user_id]]\n",
        "  for i in range(len(real_rating)):\n",
        "    ideal_recommendations[i].append(real_rating[i])\n",
        "  ideal_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  print(\"My recommendations: \", [i[0] for i in recommendations])\n",
        "  print(\"Ideal recommendations: \", [i[0] for i in ideal_recommendations])\n",
        "\n"
      ],
      "metadata": {
        "id": "lQiUb2ocXhqI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_10(8) # Recommend 10 movies for user #8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKjAXyZNLFhq",
        "outputId": "2f4bc5e9-b9e0-4a6d-a923-65ea31dd91c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My recommendations:  [22, 50, 79, 89, 182, 294, 338, 385, 457, 550]\n",
            "Ideal recommendations:  [22, 50, 182, 79, 89, 338, 294, 550, 385, 457]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As you see, my recommendations are not far from ideal ones, based on the test data"
      ],
      "metadata": {
        "id": "axATnZIxaSkU"
      },
      "execution_count": 15,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}